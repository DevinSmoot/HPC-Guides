\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\PassOptionsToPackage{hyphens}{url} % url is loaded by hyperref
\usepackage[unicode=true]{hyperref}
\hypersetup{
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother


\date{}

\begin{document}

\section{Raspberry Pi Cluster Setup
Guide}\label{raspberry-pi-cluster-setup-guide}

\subsection{Using Raspbian Jessie
Lite}\label{using-raspbian-jessie-lite}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{Considerations to Consider before
starting}\label{considerations-to-consider-before-starting}

\begin{itemize}
\tightlist
\item
  SD card size

  \begin{itemize}
  \tightlist
  \item
    If your SD card size will vary you will want to build the head node
    using the smallest size of SD card. This will ensure that the image
    for that SD card will ALWAYS be able to be written to a similar
    sized SD or larger. If you start with a 64GB SD card you will not be
    able to write the image to a 16GB SD card.
  \end{itemize}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{Head Node}\label{head-node}

\subparagraph{Hardware:}\label{hardware}

\begin{itemize}
\tightlist
\item
  Raspberry Pi board x 1
\item
  WiPi USB dongle x 1
\item
  SD Card 16GB+ x 1
\item
  Ethernet cable x 1
\item
  HDMI cable x 1
\item
  Power cable mini-USB x 1
\end{itemize}

\subsection{Compute nodes}\label{compute-nodes}

\subparagraph{Hardware:}\label{hardware-1}

\begin{itemize}
\tightlist
\item
  Raspberry Pi board x 7
\item
  SD Card 16GB+ x 1
\item
  Ethernet cable x 1
\item
  Power cable mini-USB x 1
\end{itemize}

\subsection{Additional Hardware}\label{additional-hardware}

\begin{itemize}
\tightlist
\item
  10 Port USB hub
\item
  16 Port gigabit switch
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{Setup, Installation, and
Testing}\label{setup-installation-and-testing}

\begin{quote}
\mbox{}%
\subparagraph{Step 1 - Install operating
systems}\label{step-1---install-operating-systems}
\end{quote}

Install Raspbian Lite on SD card for head unit(s) and each compute node

\href{https://www.raspberrypi.org/downloads/raspbian/}{Raspbian Lite}

\href{https://www.raspberrypi.org/documentation/installation/installing-images/}{Raspbian
Install Guides}

\begin{quote}
\mbox{}%
\subparagraph{Step 2 - Configure head node
settings}\label{step-2---configure-head-node-settings}
\end{quote}

Setup the locale settings to make sure the correct keyboard, language,
timezone, etc are set. This will ensure we are able to enter the correct
symbols while working on the command line.

Configure Locale:

Log in with username: \textbf{pi} and password \textbf{raspberry}

\begin{verbatim}
sudo raspi-config
\end{verbatim}

==9/29/17 - Changed option numbers to correlate with updated OS Expand
the filesystem (\emph{\textbf{Option 7}}) * Select \emph{\textbf{Yes}}

Setup Localization Options (\emph{\textbf{Option 4}})

\begin{itemize}
\tightlist
\item
  Set Locale (\emph{\textbf{Option I1}})

  \begin{itemize}
  \tightlist
  \item
    Unselect \emph{\textbf{en\_GB.UTF-8}}
  \item
    Select \emph{\textbf{en\_US ISO-8859-1}}
  \item
    Select \emph{\textbf{en\_US}}
  \end{itemize}
\end{itemize}

Under Localization Options: * Set TimeZone (\emph{\textbf{Option I2}}) *
Select \emph{\textbf{America}} * Select \emph{\textbf{Chicago}}

Under Localization Options: * Set Keyboard Layout (\emph{\textbf{Option
I3}}) * Use the default selected Keyboard * Select \emph{\textbf{English
(US)}} * Use the default keyboard Layout * Select \emph{\textbf{No
compose key}} * Select \emph{\textbf{No}}

Under Localization Options: * Set Wi-Fi country (\emph{\textbf{Option
I4}}) * Select \emph{\textbf{US United States}}

On the main settings page (not under advanced options): * Set Hostname
(\emph{\textbf{Option 2}}) * Set \emph{Hostname} (\emph{\textbf{Option
A2}}) * Enter \emph{\textbf{head}}

Under Advanced options: * Set Memory Split (\emph{\textbf{Option 7}}) *
Set \emph{Memory Split} (\emph{\textbf{Option A3}}) * Enter
\emph{\textbf{16}}

\begin{itemize}
\item ~
  \subparagraph{Setup SSH service:}\label{setup-ssh-service}

  On the main screen:
\item
  Select \emph{\textbf{Interfacing Options}} (\emph{\textbf{Option 5}})

  \begin{itemize}
  \tightlist
  \item
    Select \emph{\textbf{SSH}} (\emph{\textbf{Option P2}})
  \item
    Select \emph{\textbf{Yes}}
  \item
    Select \emph{\textbf{Ok}}
  \end{itemize}
\end{itemize}

Select \emph{Finish} and \emph{Yes} to reboot

==End 9/29/17

\begin{quote}
\mbox{}%
\subparagraph{Step 3 - Configure head node
network}\label{step-3---configure-head-node-network}
\end{quote}

Set a static address for the cluster facing network interface connection
\emph{etho0}. Turn on wireless and setup wireless connection on network
interface connection \emph{wlan0}. Turn on SSH service and then reboot
the head node.

\subparagraph{\texorpdfstring{Setup
\emph{eth0}:}{Setup eth0:}}\label{setup-eth0}

Edit \emph{/etc/dhcpcd.conf}:

\texttt{sudo\ nano\ /etc/dhcpcd.conf}

Add to the end of the file:

\begin{verbatim}
interface eth0
static ip_address=192.168.10.5
static domain_name_servers=8.8.8.8
\end{verbatim}

Save and exit

\subparagraph{\texorpdfstring{Setup
\emph{wlan0}:}{Setup wlan0:}}\label{setup-wlan0}

Add wireless network credentials:

Edit \emph{/etc/wpa\_supplicant/wpa\_supplicant.conf}:

\texttt{sudo\ nano\ /etc/wpa\_supplicant/wpa\_supplicant.conf}

For connecting to a secure network add the following to the end of the
file:

\begin{verbatim}
network={
ssid="<network name>"
psk="<network password>"
}
\end{verbatim}

For connecting to an unsecure network add the following to the end of
the file:

\begin{verbatim}
network={
ssid="<network name>"
key_mgmt=NONE
}
\end{verbatim}

Reboot:

\texttt{sudo\ reboot}

\begin{quote}
\mbox{}%
\subparagraph{Step 4 - Update the
system}\label{step-4---update-the-system}
\end{quote}

\texttt{sudo\ apt\ update\ \&\&\ sudo\ apt\ upgrade\ -y}

Reboot:

\texttt{sudo\ reboot}

\begin{quote}
\mbox{}%
\subparagraph{Step 5 - IP forwarding for nodes to access
internet}\label{step-5---ip-forwarding-for-nodes-to-access-internet}
\end{quote}

Setup IP forwarding so that all compute nodes will have access to the
internet for package installation and to download any needed materials
on later use.

Log in with username: \textbf{pi} and password \textbf{raspberry}

Enable IPv4 Forwarding and Disable IPv6:

\texttt{sudo\ nano\ /etc/sysctl.conf}

Add the following lines to the end of the file (this includes the IP
forwarding rule from above):

\begin{verbatim}
# Enable IPv4 forwarding
net.ipv4.ip_forward = 1

# Disable IPv6
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv6.conf.lo.disable_ipv6 = 1
\end{verbatim}

Save and exit

Update the configuration files:

\texttt{sudo\ sysctl\ -p}

Edit and Save the iptables:

\begin{verbatim}
sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE
sudo iptables -t nat -A POSTROUTING -o wlan0 -j MASQUERADE

sudo bash -c "iptables-save > /etc/iptables.rules"
\end{verbatim}

Add settings to \emph{/etc/network/interfaces}:

\texttt{sudo\ nano\ /etc/network/interfaces}

Add the following line at the end of the wlan0 section under wpa-conf
line to make the changes persistent:

\texttt{pre-up\ iptables-restore\ \textless{}\ /etc/iptables.rules}

Save and exit

Update \emph{/etc/hosts\_ file}:

Add the following to the end of the file:

\emph{\textbf{Note:}} At this point you want to assign and name all of
your nodes that \textbf{WILL} be in your cluster and enter them in the
hosts file. Below is an example of a 6 node cluster including the head
node as one of the six. This file will be copied with the image to the
compute nodes and will save you a step of developing and deploying the
hosts file later.

\begin{verbatim}
127.0.1.1   head

192.168.10.3    nodeX
192.168.10.5    head
192.168.10.100  node0
192.168.10.101  node1
192.168.10.102  node2
192.168.10.103  node3
192.168.10.104  node4
\end{verbatim}

Reboot:

\texttt{sudo\ reboot}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{Install MPICH-3.2}\label{install-mpich-3.2}

Install prerequisite \emph{Fortran} which wil be required for compiling
MPICH. All other dependencies are already installed.

\begin{quote}
\mbox{}%
\subparagraph{Step 1 - Install Fortran}\label{step-1---install-fortran}
\end{quote}

\begin{verbatim}
sudo apt install gfortran
\end{verbatim}

\begin{quote}
\mbox{}%
\subparagraph{Step 2 - Install and Setup
MPICH3}\label{step-2---install-and-setup-mpich3}
\end{quote}

Create hpc group:

\texttt{sudo\ groupadd\ hpc}

Add pi user to hpc group:

\texttt{sudo\ usermod\ -aG\ hpc\ pi}

Create hpc directory in root:

\begin{verbatim}
sudo mkdir -p /software/lib

cd /software/lib
\end{verbatim}

Take ownership of /software:

\texttt{sudo\ chown\ -R\ pi:hpc\ /software}

Create build and install directory inside mpich3 directory:

\begin{verbatim}
cd /software/lib

mkdir mpich_3.2

cd mpich_3.2

mkdir build install
\end{verbatim}

Download mpich3 and untar:

\begin{verbatim}
wget http://www.mpich.org/static/downloads/3.2/mpich-3.2.tar.gz

tar xvfz mpich-3.2.tar.gz
\end{verbatim}

Compile and install mpich3:

\begin{verbatim}
cd build

/software/lib/mpich_3.2/mpich-3.2/configure --prefix=/software/lib/mpich_3.2/install

make

make install
\end{verbatim}

Activate environment variable:

\texttt{export\ PATH=/software/lib/mpich\_3.2/install/bin:\$PATH}

Add path to environment variables for persistance:

\texttt{sudo\ nano\ \textasciitilde{}/.bashrc}

Add the following to the end of the file:

\begin{verbatim}
# MPICH-3.2
export PATH="/software/lib/mpich_3.2/install/bin:$PATH"
\end{verbatim}

\begin{quote}
\mbox{}%
\subparagraph{Step 3 - Create list of nodes for
MPI:}\label{step-3---create-list-of-nodes-for-mpi}
\end{quote}

This list of nodes will need to be updated as you add nodes later.
Initially you will only have the head node.

Create node list:

\begin{verbatim}
cd ~
sudo nano nodelist
\end{verbatim}

Add the head node ip address to the list:

\begin{verbatim}

_**Note:**_ Anytime you need to add a node to the cluster make sure to add it here as well as */etc/hosts* file.

> ##### Step 4 - Test MPI

###### Test 1 - Hostname Test
\end{verbatim}

cd \textasciitilde{}

mpiexec -f nodelist hostname ```

Should return:

\texttt{head}

Test 2 - Calculate Pi

\texttt{mpiexec\ -f\ nodelist\ -n\ 2\ /software/lib/mpich\_3.2/build/examples/cpi}

Should return similar:

\begin{verbatim}
Process 0 of 2 is on head
Process 1 of 2 is on head
pi is approximately 3.1415926544231318, Error is 0.0000000008333387
wall clock time = 0.003250
\end{verbatim}

\begin{quote}
\mbox{}%
\subparagraph{Step 5 - Setup SSH keys}\label{step-5---setup-ssh-keys}
\end{quote}

\emph{\textbf{Note:}} \emph{Must be executed from head node as pi user}

Generate SSH key:

\begin{verbatim}
cd ~

ssh-keygen -t rsa -C "<username>@swosubta" -f ~/.ssh/id_rsa
\end{verbatim}

Press `Enter' for passphrase

Press `Enter' for same passphrase

Transfer the key to the authorized\_keys file:

\begin{verbatim}
cat ~/.ssh/id_rsa.pub > ~/.ssh/authorized_keys
\end{verbatim}

\subsection{Save SD Image}\label{save-sd-image}

At this point you will want to save an image of the head node. This will
give you a fall back point if you make mistakes moving forward. You will
also use this image to begin your node image.

Using the same guide as described in the beginning you will want to
reverse the process of writing an image to the SD and \emph{read} an
image from the SD and save that image to your PC. Now you have saved
your SD like a checkpoint.

Sample name for SD image:
\texttt{compute\_node\_mpi\_stage\_2017\_01\_03}

\subsection{Create Node image}\label{create-node-image}

The overview of this process:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Save image of \emph{head node}.
\item
  On a new SD card write the \emph{head node} image you just saved.
\item
  Boot the second SD you just created from the head node and make the
  following changes for ``Creating a Generic Node Image''.
\item
  Save image of newly created \emph{generic compute node}.
\end{enumerate}

At this point you have a copy of both the \emph{head node} and
\emph{generic comput node} at the MPI stage. This is a checkpoint that
you can fall back to if there are errors after this point.

This will be a repeatable process when completed. You will setup an
initial \emph{compute node} image using your saved \emph{head node}
image. You will go in and change specific settings to \emph{generic
settings}. Doing this will allow you to always access your \emph{generic
compute node} image at the same IP address and hostname. You will then
be able to set up the compute node image to a specific IP address and
hostname. Following this process will allow for prompt and efficient
deployment of a cluster.

\href{https://www.raspberrypi.org/documentation/installation/installing-images/}{Raspbian
Install Guides}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{Create Generic Node image}\label{create-generic-node-image}

This will be a repeatable process when completed. You will setup an
initial \emph{compute node} image using your saved \emph{head node}
image. You will go in and change specific settings to \emph{generic
settings}. Doing this will allow you to always access your \emph{generic
compute node} image at the same IP address and hostname. You will then
be able to set up the compute node image to a specific IP address and
hostname. Following this process will allow for prompt and efficient
deployment of a cluster.

\begin{quote}
\mbox{}%
\subparagraph{Step 1 - Boot image and
login}\label{step-1---boot-image-and-login}
\end{quote}

Log in with username: \textbf{pi} and password \textbf{raspberry}

\begin{quote}
\mbox{}%
\subparagraph{Step 2 - Enter a generic ip
address}\label{step-2---enter-a-generic-ip-address}
\end{quote}

\texttt{sudo\ nano\ /etc/dhcpcd.conf}

Change the \emph{eth0} ip address from:

\texttt{static\ ip\_address=192.168.10.5}

To:

\texttt{static\ ip\_address=192.168.10.3}

Also add to the end of the file:

\texttt{static\ routers=192.168.10.5}

Save and exit

\begin{quote}
\mbox{}%
\subparagraph{Step 3 - Enter a generic
hostname}\label{step-3---enter-a-generic-hostname}
\end{quote}

\texttt{sudo\ nano\ /etc/hostname}

Change:

\texttt{head}

To:

\texttt{nodeX}

Save and exit

\begin{quote}
\mbox{}%
\subparagraph{Step 4 - Edit hosts file}\label{step-4---edit-hosts-file}
\end{quote}

\texttt{sudo\ nano\ /etc/hosts}

Change:

\texttt{127.0.1.1\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ head}

To:

\texttt{127.0.1.1\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ nodeX}

Save and exit

\begin{quote}
\mbox{}%
\subparagraph{Step 5 - Remove wireless connection
information}\label{step-5---remove-wireless-connection-information}
\end{quote}

Edit \emph{interfaces} file:

\texttt{sudo\ nano\ /etc/network/interfaces}

\begin{verbatim}
allow-hotplug wlan0
iface wlan0 inet manual
wpa-conf /etc/wpa_supplicant/wpa_supplicant.conf

pre-up iptables-restore < /etc/iptables.rules
\end{verbatim}

Edit \emph{wpa\_supplicant.conf}:

\texttt{sudo\ nano\ /etc/wpa\_supplicant/wpa\_supplicant.conf}

Remove this section if you have a secure network:

\begin{verbatim}
network={
ssid="<network name>"
psk="<network password>"
}
\end{verbatim}

Remove this section if you have an unsecure network:

\begin{verbatim}
network={
ssid="<network name>"
key_mgmt=NONE
}
\end{verbatim}

\begin{quote}
\mbox{}%
\subparagraph{Step 6 - Shutdown and create a new image of the
SD}\label{step-6---shutdown-and-create-a-new-image-of-the-sd}
\end{quote}

\texttt{sudo\ shutdown\ -h\ now}

Now you will go back to WinDiskImager32 and save the image as a node
image. This is a generic node image that you can quickly deploy and use
to set up your cluster with.

Sample name for SD image:
\texttt{compute\_node\_mpi\_stage\_2017\_01\_03}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{Setup Generic Node image}\label{setup-generic-node-image}

\href{https://www.raspberrypi.org/documentation/installation/installing-images/}{Raspbian
Install Guides}

\begin{quote}
\mbox{}%
\subparagraph{Step 1 - Copy generic node image created earlier to an SD
card using
WinDiskImager32.}\label{step-1---copy-generic-node-image-created-earlier-to-an-sd-card-using-windiskimager32.}
\end{quote}

\begin{quote}
\mbox{}%
\subparagraph{Step 2 - Boot and login to your
system}\label{step-2---boot-and-login-to-your-system}
\end{quote}

Log in with username: \textbf{pi} and password \textbf{raspberry}

\begin{quote}
\mbox{}%
\subparagraph{\texorpdfstring{Step 3 - Adjust \emph{/etc/hostname}
file}{Step 3 - Adjust /etc/hostname file}}\label{step-3---adjust-etchostname-file}
\end{quote}

\texttt{sudo\ nano\ /etc/hostname}

Change:

\texttt{nodeX}

To:

\texttt{node0}

Save and exit

\emph{\textbf{Note:}} This number will increment by one each time you
add a node and must be unique on your cluster.

\begin{quote}
\mbox{}%
\subparagraph{\texorpdfstring{Step 4 - Adjust
\emph{/etc/dhcpcd.conf}}{Step 4 - Adjust /etc/dhcpcd.conf}}\label{step-4---adjust-etcdhcpcd.conf}
\end{quote}

\texttt{sudo\ nano\ /etc/dhcpcd.conf}

Change the \emph{eth0} ip address from:

\texttt{static\ ip\_address=192.168.10.3}

To:

\texttt{static\ ip\_address=192.168.10.100}

Save and exit

\begin{quote}
\mbox{}%
\subparagraph{Step 5 - Edit hosts file}\label{step-5---edit-hosts-file}
\end{quote}

\texttt{sudo\ nano\ /etc/hosts}

Change:

\texttt{127.0.1.1\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ nodeX}

To:

\texttt{127.0.1.1\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ node0}

Save and exit

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{Deploy Head Node SSH Key}\label{deploy-head-node-ssh-key}

Issue the following command for each node:

\texttt{cat\ \textasciitilde{}/.ssh/authorized\_keys\ \textbar{}\ ssh\ pi@nodeX\ "cat\ \textgreater{}\ \textasciitilde{}/.ssh/authorized\_keys"}

==POSSIBLE CHANGE==
\texttt{rsync\ -a\ -\/-rsync-path="sudo\ rsync"\ \textasciitilde{}/.ssh/authorized\_keys\ pi@nodeX:\textasciitilde{}/.ssh/authorized\_keys}
==END CHANGE==

\emph{\textbf{Note:}} At this point you will just do this once to
develop a compute node image with Slurm installed. After that is
complete you will create a new generic image of the compute node. Once
that is complete you can use that image to finish deploying your compute
nodes for the rest of your cluster.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{Install NTP}\label{install-ntp}

NTP is used to keep the cluster time close together using outside NTP
servers to sync with the head node. All computer nodes will sync with
the head node.

Reference: http://raspberrypi.tomasgreno.cz/ntp-client-and-server.html
http://www.pool.ntp.org/zone/north-america

\begin{quote}
\mbox{}%
\subparagraph{Head Node}\label{head-node-1}

Install NTP:
\end{quote}

\texttt{sudo\ apt\ install\ ntp}

Edit the \emph{/etc/ntp.conf}:

\texttt{sudo\ nano\ /etc/ntp.conf}

Change:

\begin{verbatim}
server 0.debian.pool.ntp.org iburst
server 1.debian.pool.ntp.org iburst
server 2.debian.pool.ntp.org iburst
server 3.debian.pool.ntp.org iburst
\end{verbatim}

To:

\begin{verbatim}
server 0.north-america.pool.ntp.org
server 1.north-america.pool.ntp.org
server 2.north-america.pool.ntp.org
server 3.north-america.pool.ntp.org
\end{verbatim}

Restart NTP:

\texttt{sudo\ /etc/init.d/ntp\ restart}

\begin{quote}
\mbox{}%
\subparagraph{Compute Node}\label{compute-node}
\end{quote}

Set Head Node as NTP server.

Edit \emph{/etc/ntp.conf}:

Under \texttt{restrict\ ::1} add:

\texttt{restrict\ 192.168.10.0\ mask\ 255.255.255.0}

Change:

\texttt{\#broadcast\ 192.168.123.255}

To:

\texttt{broadcast\ 192.168.10.255}

Restart NTP service:

\texttt{sudo\ /etc/init.d/ntp\ restart}

\subsection{Install Slurm on Compute
Node}\label{install-slurm-on-compute-node}

\begin{quote}
\mbox{}%
\subparagraph{\texorpdfstring{Step 1 - Copy Slurm configuration and
Munge files from \emph{Head
Node}}{Step 1 - Copy Slurm configuration and Munge files from Head Node}}\label{step-1---copy-slurm-configuration-and-munge-files-from-head-node}
\end{quote}

\textbf{On \emph{head node}:}

\texttt{rsync\ -a\ -\/-rsync-path="sudo\ rsync"\ /etc/munge/munge.key\ pi@nodeX:/etc/slurm-llnl/slurm.conf}

\texttt{rsync\ -a\ -\/-rsync-path="sudo\ rsync"\ /etc/slurm-llnl/slurm.conf\ pi@nodeX:/etc/slurm-llnl/slurm.conf}

\begin{quote}
\mbox{}%
\subparagraph{Step 2 - Install Slurm
daemon}\label{step-2---install-slurm-daemon}
\end{quote}

\textbf{On \emph{node0 node}:}

SSH into \emph{node0}:

\begin{verbatim}
sudo apt install slurmd slurm-client
sudo ln -s /var/lib/slurm-llnl /var/lib/slurm
\end{verbatim}

Finish install and start Slurm and Munge:

\begin{verbatim}
sudo systemctl enable slurmd.service
sudo systemctl restart slurmd.service
sudo systemctl enable munge.service
sudo systemctl restart munge.service
\end{verbatim}

Verify Slurm daemon is running:

\texttt{sudo\ systemctl\ status\ slurmd.service}

Will return feedback to the screen. Verify \emph{Active} line states:
\emph{\textbf{active (running)}}.

Verify Munge is running:

\texttt{sudo\ systemctl\ status\ munge.service}

Will return feedback to the screen. Verify \emph{Active} line states:
\emph{\textbf{active (running)}}.

\begin{quote}
\mbox{}%
\subparagraph{Step 3 - Add user to Slurm
group}\label{step-3---add-user-to-slurm-group}
\end{quote}

\texttt{sudo\ adduser\ pi\ slurm}

\begin{quote}
\mbox{}%
\subparagraph{Step 4 - Add and take ownership of Slurm log
folder}\label{step-4---add-and-take-ownership-of-slurm-log-folder}
\end{quote}

\begin{verbatim}
sudo mkdir -p /var/log/slurm/accounting

sudo chown -R slurm:slurm /var/log/slurm
\end{verbatim}

Execute on \emph{head node}:

\begin{verbatim}
sudo scontrol reconfigure

sudo scontrol update nodename="node[0-6]" state=resume
-If this command throws an invalid nodename error:
try updating each node individually with the command:
sudo scontrol update NodeName="nodeX" state=resume

sinfo
\end{verbatim}

This should show all nodes in an idle state.

\subsection{Deploying the Rest of the
Cluster}\label{deploying-the-rest-of-the-cluster}

By now you have developed a head node image that contains both MPI and
Slurm. You have also developed a compute node image that contains both
MPI and Slurm as well. Now you should go back to the instructions for
``Create Node Image'' to save both images and then use the compute node
image to finish deploying your cluster. Saving these images at each
stage gives you different configurations that you can easily deploy in
the future and also allows you to have a checkpoint in case something
goes wrong. You can write the saved node image to your SD and start from
that point rather then starting from the beginning.

\subsection{Add an ethernet adapter}\label{add-an-ethernet-adapter}

Edit \emph{/etc/network/interfaces} file:

\texttt{sudo\ nano\ /etc/network/interfaces}

Add below eth0 section:

\begin{verbatim}
auto eth1
iface eth1 inet manual
\end{verbatim}

Change or add iptables rule to end of file:

\texttt{pre-up\ iptables-restore\ \textless{}\ /etc/iptables\_wired.rules}

Create iptables rules file:

\texttt{sudo\ nano\ /etc/iptables\_wired.rules}

\begin{verbatim}
# Generated by iptables-save v1.6.0 on Wed Sep 20 04:58:42 2017
*nat
:PREROUTING ACCEPT [3:228]
:INPUT ACCEPT [3:228]
:OUTPUT ACCEPT [3:228]
:POSTROUTING ACCEPT [0:0]
-A POSTROUTING -o eth0 -j MASQUERADE
-A POSTROUTING -o eth1 -j MASQUERADE
COMMIT
# Completed on Wed Sep 20 04:58:42 2017
\end{verbatim}

\subsubsection{Disable WiFi}\label{disable-wifi}

Edit \emph{/etc/wpa\_supplicant/wpa\_supplicant.conf} file:

\texttt{sudo\ nano\ /etc/wpa\_supplicant/wpa\_supplicant.conf}

Comment out the \texttt{network=\{\ connection\ information\ \}} section
(all lines)

Disable eth1 adapter:

\texttt{sudo\ ifconfig\ eth1\ down}

Reboot:

\texttt{sudo\ reboot}

Now all traffic for the cluster is routed through eth0 and out eth1 to
the internet. Any returning traffic or downloads come in via eth1 and
through eth0 to the cluster unless its meant for the head node.

\subsubsection{Troubleshooting Section:}\label{troubleshooting-section}

\subparagraph{NETWORK UNREACHABLE:}\label{network-unreachable}

When experiencing network connectivity problems with compute nodes:

\begin{itemize}
\tightlist
\item
  Flush the iptables in Memory
\end{itemize}

\texttt{sudo\ iptables\ -\/-flush}

\begin{itemize}
\tightlist
\item
  Delete the rules file
\end{itemize}

\texttt{sudo\ rm\ -rf\ /etc/iptables.rules}

\begin{itemize}
\tightlist
\item
  Rebuild the rules and file Repeat the IP tables section of the guide,
  starting with the commands:
\end{itemize}

\begin{verbatim}
sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE
sudo iptables -t nat -A POSTROUTING -o wlan0 -j MASQUERADE
\end{verbatim}

Save the iptables.rules file:

\begin{verbatim}
sudo bash -c "iptables-save > /etc/iptables.rules"
\end{verbatim}

Check for the iptable rules in the \emph{/etc/network/interfaces file}:

Make sure that the line below is present and not commented out:

\texttt{pre-up\ iptables-restore\ \textless{}\ /etc/iptables.rules}

If it is missing then add it to the end of the file. Save and exit.

\subparagraph{MPI ISSUES:}\label{mpi-issues}

If mpiexec command fails to execute, stalls, or displays an error
message about an unreadable path file: * Mpich3 could be i * the wrong
directory * Make sure the export path correlates to the actual install
path for MPICH3 * Reinstalling MPICH3 and setting up the proper
environment variables can fix many problems, re-evaluate the MPICH3
install instructions and verify all settings before attempting a
reinstall.

\subparagraph{SSH ISSUES:}\label{ssh-issues}

If the Pi is displaying SSH errors when running the mpiexec command:
Check the problematic node's authorized\_keys file, and compare it with
the head node's authorized\_keys file.

Check the file by going to the SSH directory:

\begin{verbatim}
cd ~/.ssh
\end{verbatim}

Now check the file information for \emph{authorized\_keys} file:

\begin{verbatim}
ls -ls
\end{verbatim}

The filesize is listed after the owner and group names.

These file should be identical in length, if not redistribute the head
node's authorized\_keys file to the compute node using the following
command:

\texttt{sudo\ cat\ \textasciitilde{}/.ssh/authorized\_keys\ \textbar{}\ ssh\ pi@nodeX\ "cat\ \textgreater{}\ \textasciitilde{}/.ssh/authorized\_keys"}

==POSSIBLE CHANGE== Use the new rsync instructions ==END CHANGE==

\subparagraph{COMMANDS TO CHECK SERVICE
STATUSES:}\label{commands-to-check-service-statuses}

These commands do the same thing, just with a different syntax:

\texttt{sudo\ systemctl\ {[}start,stop,restart,status{]}\ \textless{}service\ name\textgreater{}}

\texttt{sudo\ service\ \textless{}service\ name\textgreater{}\ {[}start,stop,restart,status{]}}

\texttt{sudo\ /etc/init.d/\textless{}service\ name\textgreater{}\ {[}start,stop,restart,status{]}}

\subparagraph{ENABLING/DISABLING NETWORK INTERFACE
CONNECTIONS:}\label{enablingdisabling-network-interface-connections}

Disable the specified connection

\texttt{sudo\ ifdown\ \textless{}connection\ name\textgreater{}}

Enable the specified connection

\texttt{sudo\ ifup\ \textless{}connection\ name\textgreater{}}

\subparagraph{SLURM ISSUES:}\label{slurm-issues}

Make sure the slurm.conf file is identical across all nodes.

When running the service status command, read the error messages that
are displayed: \emph{\textbf{these messages are vital in order to
troubleshoot current problems}}.

PROBLEMATIC NODES:

On many occasions, certain nodes fail to work because of a
software/hardware malfunction. This can be fixed by removing and
reinstalling the software. Hardware problems can be fixed by
reformatting the node's SD card, and rewriting it with a functional node
image. Also check each Ethernet cable for weaknesses, and verify that
each node in the cluster is properly connected.

-For Pi 3 Clusters: The head node is connected via Wi-Fi, and each
compute node uses the head node's wireless connection to download files.

-For Pi 2 Clusters: A Wi-Pi adapter is a tested solution for
establishing a wireless connection with a Raspberry Pi model 2. Using
other wireless adapters could result in incompatible drivers or other
various issues. The head node can also be connected to the Internet via
an Ethernet cable.

\subsubsection{Network Diagrams}\label{network-diagrams}

Base Equipment Layer (Pictured Below)

Physical Layer (Pictured Below)

Logical Layer (Pictured Below)

Physical and Logical Layers (Pictured Below)

\subsection{}\label{section}

\subsection{References:}\label{references}

https://www.modmypi.com/blog/how-to-give-your-raspberry-pi-a-static-ip-address-update

https://www.raspberrypi.org/forums/viewtopic.php?f=28\&t=44609

http://weworkweplay.com/play/automatically-connect-a-raspberry-pi-to-a-wifi-network/

https://www.raspberrypi.org/forums/viewtopic.php?f=36\&t=162096

https://www.raspberrypi.org/forums/viewtopic.php?t=118804\&p=808453

https://www.raspberrypi.org/forums/viewtopic.php?f=28\&t=37575

http://unix.stackexchange.com/questions/88100/importing-data-from-a-text-file-to-a-bash-script

http://www.tldp.org/LDP/abs/html/arrays.html

http://how-to.wikia.com/wiki/How\_to\_read\_command\_line\_arguments\_in\_a\_bash\_script

http://ryanstutorials.net/bash-scripting-tutorial/bash-variables.php

http://stackoverflow.com/questions/19996089/use-ssh-to-start-a-background-process-on-a-remote-server-and-exit-session

http://stackoverflow.com/questions/29142/getting-ssh-to-execute-a-command-in-the-background-on-target-machine

http://www.igeekstudio.com/blog/setting-up-ganglia-and-hadoop-on-raspberry-pi

http://ccm.net/faq/2540-linux-create-your-own-command

https://github.com/XavierBerger/RPi-Monitor

https://www.raspberrypi.org/blog/visualising-core-load-on-the-pi-2/

https://github.com/davidsblog/rCPU

https://raseshmori.wordpress.com/2012/10/14/install-hadoop-nextgen-yarn-multi-node-cluster/

https://www.packtpub.com/hardware-and-creative/raspberry-pi-super-cluster

\end{document}
